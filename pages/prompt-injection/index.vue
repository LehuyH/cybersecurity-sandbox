<template>
    <div class="hero h-full flex justify-center items-center">
        <div class="hero-content text-left">
            <div class="max-w-md">
                <h1 class="text-5xl font-bold">Prompt Injection</h1>
                <p class="py-6">
                    A type of attack that exploits vulnerabilities in Language Models (LLMs) by manipulating their inputs or prompts.
                    <br/><br/>
                    With this challenge, you'll simulate attacks on a real LLM and learn how to defend against them.
                </p>
                <aside class="flex gap-2">
                    <NuxtLink to="/prompt-injection/translate" class="btn btn-primary">Get Started</NuxtLink>
                    <NuxtLink to="/challenges" class="btn btn-neutral">Back</NuxtLink>
                </aside>
            </div>
        </div>
    </div>
</template>